{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T21:12:29.391463Z",
     "start_time": "2019-08-15T21:12:29.385278Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d  # because we will be using projection='3d'\n",
    "from ipywidgets import interact_manual, FloatSlider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T21:12:29.616191Z",
     "start_time": "2019-08-15T21:12:29.603311Z"
    }
   },
   "outputs": [],
   "source": [
    "def graph3d_wrapper(func, xlabel:str, ylabel:str, zlabel:str, title:str, xlower:float, xupper:float,xstep:float,\n",
    "                    ylower:float, yupper:float, ystep:float, proj:bool):\n",
    "    \"\"\"\n",
    "    Wrapper function for making the plotting function easily usable for 'interact_manual'.\n",
    "    Set values to all arguments except the one manipulated by 'FloatSlider'.\n",
    "    \"\"\"\n",
    "    \n",
    "    def graph3d(cov):\n",
    "\n",
    "        fig = plt.figure()\n",
    "        ax = fig.gca(projection='3d')\n",
    "        \n",
    "        xs = np.arange(xlower, xupper, xstep)\n",
    "        ys = np.arange(ylower, yupper, ystep)\n",
    "        xs, ys = np.meshgrid(xs, ys)\n",
    "        zs = func(xs, ys, cov)\n",
    "        \n",
    "        ax.plot_surface(xs, ys, zs, alpha=0.7, cmap=cm.viridis)\n",
    "        if proj:\n",
    "            cset = ax.contourf(xs, ys, zs, zdir='z', offset=zs.min(), cmap=cm.coolwarm)\n",
    "\n",
    "        ax.set_xlim(xlower, xupper); ax.set_ylim(ylower, yupper); ax.set_zlim(zs.min(), zs.max())\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(xlabel); ax.set_ylabel(ylabel); ax.set_zlabel(zlabel)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return graph3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of multi-variate normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='normal-2d.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of Mahalanobis distance, $\\triangle$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\triangle = ({\\bf x}-{\\boldsymbol \\mu})^T \\boldsymbol{\\Sigma} ({\\bf x}-{\\boldsymbol \\mu})$, which reduces to Euclidean distance when $\\boldsymbol{\\Sigma}$ is the identity matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand bi-variate Gaussian through algebraic expansion of $\\triangle$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concepts needed:\n",
    "\n",
    "- Recall the definition of **covariance**: $\\text{cov}({\\bf x}, {\\bf y})=\\mathbb{E}[({\\bf x}-\\mu_{\\bf x})({\\bf y}-\\mu_{\\bf y})]$. Intuitively, covariance measures the extent to which two random variables simultaneously (not necessarily w.r.t time) move above and below their means. \n",
    "\n",
    "- Recall the definition of **matrix inverse**: <img src=\"https://github.com/zhihanyang2022/Bishop-Pattern-Recognition-Notes/blob/master/pngs/matrix-inverse.png\" alt=\"matrix inverse\" width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding the expression in the exponent:\n",
    "\n",
    "- $\\bf{x}$ is $[\\bf{x}_1, \\bf{x}_2]^T$ (column vector) and ${\\boldsymbol \\mu}$ is $[\\mu_1, \\mu_2]^T$ (column vector). $\\bf{x}_1$ and $\\bf{x}_2$ can be considered as two random variables. Whether they are independent or dependent is determined by the covariance matrix.\n",
    "---\n",
    "- $\\boldsymbol{\\Sigma}$ is a 2-by-2 covariance matrix, $\\begin{bmatrix} \\text{cov}({\\bf x}_1,{\\bf x}_1) & \\text{cov}({\\bf x}_1,{\\bf x}_2) \\\\ \\text{cov}({\\bf x}_1,{\\bf x}_2) & \\text{cov}({\\bf x}_2,{\\bf x}_2) \\end{bmatrix}$. \n",
    "---\n",
    "- $({\\bf x} - {\\boldsymbol \\mu})^T = ([x_1, x_2]^T - [\\mu_1, \\mu_2]^T)^T = [x_1-\\mu_1, x_2-\\mu_2]$ is a row vector.\n",
    "---\n",
    "- $ \\begin{align} \\boldsymbol{\\Sigma}^{-1} &=\\begin{bmatrix} \\text{cov}({\\bf x}_1,{\\bf x}_1) & \\text{cov}({\\bf x}_1,{\\bf x}_2) \\\\ \\text{cov}({\\bf x}_1,{\\bf x}_2) & \\text{cov}({\\bf x}_2,{\\bf x}_2) \\end{bmatrix}^{-1} \\\\ &= \\frac{1}{\\text{det}(\\boldsymbol{\\Sigma})} \\begin{bmatrix} \\text{cov}({\\bf x}_2,{\\bf x}_2) & - \\text{cov}({\\bf x}_1,{\\bf x}_2) \\\\ - \\text{cov}({\\bf x}_1,{\\bf x}_2) & \\text{cov}({\\bf x}_1,{\\bf x}_1) \\end{bmatrix} \\\\ &= \\frac{1}{\\text{cov}({\\bf x}_1,{\\bf x}_1)\\text{cov}({\\bf x}_2,{\\bf x}_2)-\\text{cov}({\\bf x}_1,{\\bf x}_2)^2} \\begin{bmatrix} \\text{cov}({\\bf x}_2,{\\bf x}_2) & - \\text{cov}({\\bf x}_1,{\\bf x}_2) \\\\ - \\text{cov}({\\bf x}_1,{\\bf x}_2) & \\text{cov}({\\bf x}_1,{\\bf x}_1) \\end{bmatrix} \\\\ &= \\begin{bmatrix} \\frac{\\text{cov}({\\bf x}_2,{\\bf x}_2)}{\\text{cov}({\\bf x}_1,{\\bf x}_1)\\text{cov}({\\bf x}_2,{\\bf x}_2)-\\text{cov}({\\bf x}_1,{\\bf x}_2)^2} & - \\frac{\\text{cov}({\\bf x}_1,{\\bf x}_2)}{\\text{cov}({\\bf x}_1,{\\bf x}_1)\\text{cov}({\\bf x}_2,{\\bf x}_2)-\\text{cov}({\\bf x}_1,{\\bf x}_2)^2} \\\\ - \\frac{\\text{cov}({\\bf x}_1,{\\bf x}_2)}{\\text{cov}({\\bf x}_1,{\\bf x}_1)\\text{cov}({\\bf x}_2,{\\bf x}_2)-\\text{cov}({\\bf x}_1,{\\bf x}_2)^2} & \\frac{\\text{cov}({\\bf x}_1,{\\bf x}_1)}{\\text{cov}({\\bf x}_1,{\\bf x}_1)\\text{cov}({\\bf x}_2,{\\bf x}_2)-\\text{cov}({\\bf x}_1,{\\bf x}_2)^2} \\end{bmatrix} \\\\ \\end{align}$\n",
    "---\n",
    "- $\\begin{align} ({\\bf x} - {\\boldsymbol \\mu})^T \\boldsymbol{\\Sigma}^{-1}({\\bf x} - {\\boldsymbol \\mu}) &= [x_1-\\mu_1, x_2-\\mu_2] \\begin{bmatrix} \\frac{\\text{cov}({\\bf x}_2,{\\bf x}_2)}{\\text{cov}({\\bf x}_1,{\\bf x}_1)\\text{cov}({\\bf x}_2,{\\bf x}_2)-\\text{cov}({\\bf x}_1,{\\bf x}_2)^2} & - \\frac{\\text{cov}({\\bf x}_1,{\\bf x}_2)}{\\text{cov}({\\bf x}_1,{\\bf x}_1)\\text{cov}({\\bf x}_2,{\\bf x}_2)-\\text{cov}({\\bf x}_1,{\\bf x}_2)^2} \\\\ - \\frac{\\text{cov}({\\bf x}_1,{\\bf x}_2)}{\\text{cov}({\\bf x}_1,{\\bf x}_1)\\text{cov}({\\bf x}_2,{\\bf x}_2)-\\text{cov}({\\bf x}_1,{\\bf x}_2)^2} & \\frac{\\text{cov}({\\bf x}_1,{\\bf x}_1)}{\\text{cov}({\\bf x}_1,{\\bf x}_1)\\text{cov}({\\bf x}_2,{\\bf x}_2)-\\text{cov}({\\bf x}_1,{\\bf x}_2)^2} \\end{bmatrix} [{\\bf x}_1-\\mu_1, {\\bf x}_2-\\mu_2]^T \\\\ &= [({\\bf x}_1-\\mu_1)^2\\frac{\\text{cov}({\\bf x}_2,{\\bf x}_2)}{\\text{cov}({\\bf x}_1,{\\bf x}_1)\\text{cov}({\\bf x}_2,{\\bf x}_2)-\\text{cov}({\\bf x}_1,{\\bf x}_2)^2}- ({\\bf x}_1-\\mu_1)({\\bf x}_2-\\mu_2)\\frac{\\text{cov}({\\bf x}_1,{\\bf x}_2)}{\\text{cov}({\\bf x}_1,{\\bf x}_1)\\text{cov}({\\bf x}_2,{\\bf x}_2)-\\text{cov}({\\bf x}_1,{\\bf x}_2)^2} -({\\bf x}_2-\\mu_2)({\\bf x}_1-\\mu_1)\\frac{\\text{cov}({\\bf x}_1,{\\bf x}_2)}{\\text{cov}({\\bf x}_1,{\\bf x}_1)\\text{cov}({\\bf x}_2,{\\bf x}_2)-\\text{cov}({\\bf x}_1,{\\bf x}_2)^2}+({\\bf x}_2-\\mu_2)^2\\frac{\\text{cov}({\\bf x}_1,{\\bf x}_1)}{\\text{cov}({\\bf x}_1,{\\bf x}_1)\\text{cov}({\\bf x}_2,{\\bf x}_2)-\\text{cov}({\\bf x}_1,{\\bf x}_2)^2}]  \\end{align}$\n",
    "\n",
    "---\n",
    "\n",
    "- Assume that we are modelling normalized data, that is, data with zero mean ($\\mu_1=0$, $\\mu_2=0$) and unit variance, then $\\text{cov}({\\bf x}_1, {\\bf x}_1)=1$ and $\\text{cov}({\\bf x}_2, {\\bf x}_2)=1$. As a result, $-1 \\leq \\text{cov}({\\bf x}_1, {\\bf x}_2) \\leq 1$ and $0 \\leq \\text{cov}({\\bf x}_1, {\\bf x}_2)^2 \\leq 1$.\n",
    "\n",
    "---\n",
    "\n",
    "- $ \\begin{align} ({\\bf x} - {\\boldsymbol \\mu})^T \\boldsymbol{\\Sigma}^{-1}({\\bf x} - {\\boldsymbol \\mu}) &= {\\bf x}_1^2\\frac{1}{1-\\text{cov}({\\bf x}_1,{\\bf x}_2)^2} - 2{\\bf x}_1{\\bf x}_2\\frac{\\text{cov}({\\bf x}_1,{\\bf x}_2)}{1-\\text{cov}({\\bf x}_1,{\\bf x}_2)^2} + {\\bf x}_2^2\\frac{1}{1-\\text{cov}({\\bf x}_1,{\\bf x}_2)^2} \\\\ &= \\color{red}{- \\frac{1}{2}{\\bf x}_1^2\\frac{1}{1-\\text{cov}({\\bf x}_1,{\\bf x}_2)^2}} \\color{green}{+ {\\bf x}_1{\\bf x}_2\\frac{\\text{cov}({\\bf x}_1,{\\bf x}_2)}{1-\\text{cov}({\\bf x}_1,{\\bf x}_2)^2}} \\color{red}{- \\frac{1}{2}{\\bf x}_2^2\\frac{1}{1-\\text{cov}({\\bf x}_1,{\\bf x}_2)^2}} \\\\ &= \\color{red}{- a {\\bf x}_1^2} \\color{green}{+ b{\\bf x}_1{\\bf x}_2} \\color{red}{- a {\\bf x}_2^2} \\text{ where } a \\text{ and } b \\text{ are constants.} \\end{align} $\n",
    "\n",
    "---\n",
    "\n",
    "- I name the two terms in red **\"quadratic terms\"** simply because they form <u> concave quadratic surfaces</u> with <u>perfect rotational symmetry about the z-axis</u>.\n",
    "- I name the term in green **\"covariance term\"**. It deserves a name of its own because it <u>modifies the shape of quadratic surfaces</u> when added to the quadratic terms. The extent to which it does this depends on the magnitude of covariance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize quadratic terms, $\\color{red}{- \\frac{1}{2}{\\bf x}_1^2\\frac{1}{1-\\text{cov}({\\bf x}_1,{\\bf x}_2)^2}}\\color{red}{- \\frac{1}{2}{\\bf x}_2^2\\frac{1}{1-\\text{cov}({\\bf x}_1,{\\bf x}_2)^2}}$\n",
    "\n",
    "The higher the magnitude of the covariance (regardless or sign, due to the fact that the covariance is squared):\n",
    "- the higher the magnitude of the quadratic terms (negatively) and \n",
    "- the sharper the exponentiated surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T21:12:31.182720Z",
     "start_time": "2019-08-15T21:12:31.177134Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def quadratic_term(xs, ys, cov):\n",
    "    zs = np.zeros(xs.shape)\n",
    "    for i in range(xs.shape[0]):\n",
    "        for j in range(xs.shape[1]):\n",
    "            z = - 0.5 * (1 / (1 - cov**2)) * (xs[i, j]**2 + ys[i, j]**2)  # quadratic term formula\n",
    "            zs[i][j] = z\n",
    "    return zs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T21:12:31.399434Z",
     "start_time": "2019-08-15T21:12:31.359730Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea5c312700d443518e7dcb5488360741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='cov', max=0.9, min=-0.9, step=0.01), Button(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quadratic_term_plotter = graph3d_wrapper(quadratic_term, \n",
    "                                         'x1', 'x2', 'Quadratic Term', 'Quadratic Term', \n",
    "                                         -5, 5, 0.05, -5, 5, 0.05, \n",
    "                                         proj=True)\n",
    "interact_manual(quadratic_term_plotter, cov=FloatSlider(min=-0.9, max=0.9, step=1e-2), continuous_update=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T21:12:31.532205Z",
     "start_time": "2019-08-15T21:12:31.495690Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5bed5011b0f437d8903df1db1a7f7dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='cov', max=0.9, min=-0.9, step=0.01), Button(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exp_quadratic_term_plotter = graph3d_wrapper(lambda xs, ys, cov : np.e ** quadratic_term(xs, ys, cov), \n",
    "                                             'x1', 'x2', 'exp(Quadratic Term)', 'exp(Quadratic Term)', \n",
    "                                             -5, 5, 0.05, -5, 5, 0.05, \n",
    "                                             proj=True)\n",
    "_ = interact_manual(exp_quadratic_term_plotter, cov=FloatSlider(min=-0.9, max=0.9, step=1e-2), continuous_update=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize negative covariance term, $\\color{green}{{\\bf x}_1{\\bf x}_2\\frac{\\text{cov}({\\bf x}_1,{\\bf x}_2)}{1-\\text{cov}({\\bf x}_1,{\\bf x}_2)^2}} \\text{ when  } \\text{cov}({\\bf x}_1, {\\bf x}_2) < 0$\n",
    "\n",
    "${\\bf x}_1 {\\bf x}_2$ is multiplied by a negative scalar.\n",
    "\n",
    "- The covariance term is positive if ${\\bf x}_1 {\\bf x}_2$ is negative, which happens in second and fourth quadrants of the outcome space.\n",
    "- The covariance term is negative if ${\\bf x}_1 {\\bf x}_2$ is positive, which happens in first and third quadrants of the outcome space.\n",
    "\n",
    "|  Quadrants / Term  |      covariance term     |      exp(covariance term)     |\n",
    "|:--------------------------:|:------------------------:|:-----------------------------:|\n",
    "|  first and third quadrant  | negative, grows linearly |        converge to zero       |\n",
    "| second and fourth quadrant | positive, grows linearly | positive, grows exponentially |\n",
    "    \n",
    "A similar analysis can be done easily for positive covariance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T21:12:31.807378Z",
     "start_time": "2019-08-15T21:12:31.802328Z"
    }
   },
   "outputs": [],
   "source": [
    "def covariance_term(xs, ys, cov):\n",
    "    zs = np.zeros(xs.shape)\n",
    "    for i in range(xs.shape[0]):\n",
    "        for j in range(xs.shape[1]):\n",
    "            z = xs[i, j] * ys[i, j] * cov / (1 - cov**2)  # covariance term formula\n",
    "            zs[i][j] = z\n",
    "    return zs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T21:12:31.999978Z",
     "start_time": "2019-08-15T21:12:31.965300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d73a2875f0b4fb0a78192114378c376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='cov', max=0.9, min=-0.9, step=0.01), Button(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "covariance_term_plotter = graph3d_wrapper(covariance_term, \n",
    "                                          'x1', 'x2', 'Covariance Term', 'Covariance Term', \n",
    "                                          -5, 5, 0.05, -5, 5, 0.05, \n",
    "                                          proj=True)\n",
    "interact_manual(covariance_term_plotter, cov=FloatSlider(min=-0.9, max=0.9, step=1e-2), continuous_update=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T21:12:32.186416Z",
     "start_time": "2019-08-15T21:12:32.137816Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bbaf9ca3acb49d2812a75f792cb6d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='cov', max=0.9, min=-0.9, step=0.01), Button(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exp_covariance_term_plotter = graph3d_wrapper(lambda xs, ys, cov : np.e ** covariance_term(xs, ys, cov), \n",
    "                                              'x1', 'x2', 'exp(Covariance Term)', 'exp(Covariance Term)', \n",
    "                                              -5, 5, 0.05, -5, 5, 0.05, \n",
    "                                              proj=True)\n",
    "interact_manual(exp_covariance_term_plotter, cov=FloatSlider(min=-0.9, max=0.9, step=1e-2), continuous_update=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the quadratic terms and the covariance term together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T21:12:32.490075Z",
     "start_time": "2019-08-15T21:12:32.453069Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b000f349691e4a439ae40be073114989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='cov', max=0.9, min=-0.9, step=0.01), Button(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_terms_plotter = graph3d_wrapper(lambda xs, ys, cov : quadratic_term(xs, ys, cov) + covariance_term(xs, ys, cov), \n",
    "                                     'x1', 'x2', 'Both Terms', 'Both Terms', \n",
    "                                     -5, 5, 0.05, -5, 5, 0.05, \n",
    "                                     proj=True)\n",
    "interact_manual(all_terms_plotter, cov=FloatSlider(min=-0.9, max=0.9, step=1e-2), continuous_update=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T21:12:32.655737Z",
     "start_time": "2019-08-15T21:12:32.607095Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b748f06af63c4e29b3fe296693396635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='cov', max=0.9, min=-0.9, step=0.01), Button(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exp_all_terms_plotter = graph3d_wrapper(lambda xs, ys, cov : np.e ** (quadratic_term(xs, ys, cov) + covariance_term(xs, ys, cov)), \n",
    "                                        'x1', 'x2', 'exp(Both Terms)', 'exp(Both Terms)', \n",
    "                                        -5, 5, 0.05, -5, 5, 0.05, \n",
    "                                        proj=True)\n",
    "interact_manual(exp_all_terms_plotter, cov=FloatSlider(min=-0.9, max=0.9, step=1e-2), continuous_update=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Matrix inverse: https://www.mathsisfun.com/algebra/matrix-inverse.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
